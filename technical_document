Dec 2, 2017 Updates
  - [x] 1. using the same v. and n. examples from Fulda. come up with objects that we will find v. or and similarly vise versa.
  - [x] 2. adj (knife & sharps) come up examples that we are expected and similar to 1, try to find similar ones.
  - [x] 3. write a function that take a string (sentence) identify all the n. and for each n return the list of verbs that n can afford. (return as a dictionary)

  predict_word (cannons, word, word_position)
    predict word that similar to the cannons provided.
    The word_position variable indicate the word's similar to the position of the cannon.
        e.g. cannons = [(knife sharp)]; word = fire; word_position = 0;
          possible prediction: burning
    cannon can be more than one pair of word, and the algorism will average the vector differences to make prediction.

    n1 - v1 = n2 - v2
    if word = n2; pos = 0
        v2 = n2 - (n1 - v1)
    else of word = v2; pos = 1
        n2 = (n1 - v1) + v2

  pre_possible_action(sentence)
    return a dictionary where key is the noun appeared in the sentence and value is possible actions of the key

  problem 1:
    When using SpaCy to recognize noun in a sentence, some noun might be more than one word. Therefore, in the pre_possible_action function, I figure there are two possible way to resolve this problem. One is by connect them(using underscore) and use as a whole word to do prediction. The other choice was predict with the root word. see the code below:
      try:
          dictionary[word] = predict_words(canons, word, 1)
      except:
          dictionary[word] = predict_words(canons, chunk.root.text, 1)
    I therefore run a test on both to see their performance.
    SOLVED: most of the underscore version words do not have vector in the model

  problem 2:
    One of the common problem of these function being that we can not guarantee the output word be the kind of word (e.g. verb) we’d like. At the moment, I believe spaCy cannot detect word’s tag not in a sentence. Thus, I haven’t figure out a nice way to resolve this problem, Any idea on this issue?

    Also, for the same issue, weirdly Fulda has a perfect output with all verbs. I assume it's either because of the model that we used or some undocumented method that Fulda adopted.

      Fulda's prediction on "sword"
        [‘vanquish’, ‘duel’, ‘unsheathe’, ‘wield’, ‘summon’, ‘behead’, ‘battle’, ‘impale’, ‘overpower’, ‘cloak’]
      Our prediction on "sword":
        canon :: [unsheathe] : sword)
        canon :: [swords] : sword)
        canon :: [impale] : sword)
        canon :: [overpower] : sword)
        canon :: [wear] : sword)
        canon :: [Damocles_hangs] : sword)
        canon :: [vanquish] : sword)
        canon :: [sheathe] : sword)
        canon :: [don] : sword)
        canon :: [wield] : sword)
        canon :: [gallop] : horse)
    SOLVED: check Algorism 2 by Fulda. (I think this will be partly my next week work)

  proposing next week work:
    1, Replicate algorism 2 by Fulda
    2, Replicate graspable noun by Fulfa
    3, what you would suggest and how you think the research shall go? I'm kinda lost in the realm of replicating her work.

    btw, I checked her information. She is so cool!!! Ready to read her fictions!
