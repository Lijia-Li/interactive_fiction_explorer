Dec 2, 2017 Updates
  - [x] 1. using the same v. and n. examples from Fulda. come up with objects that we will find v. or and similarly vise versa.
  - [x] 2. adj (knife & sharps) come up examples that we are expected and similar to 1, try to find similar ones.
  - [x] 3. write a function that take a string (sentence) identify all the n. and for each n return the list of verbs that n can afford. (return as a dictionary)

  predict_word (cannons, word, word_position)
    predict word that similar to the cannons provided.
    The word_position variable indicate the word's similar to the position of the cannon.
        e.g. cannons = [(knife sharp)]; word = fire; word_position = 0;
          possible prediction: burning
    cannon can be more than one pair of word, and the algorism will average the vector differences to make prediction.

    n1 - v1 = n2 - v2
    if word = n2; pos = 0
        v2 = n2 - (n1 - v1)
    else of word = v2; pos = 1
        n2 = (n1 - v1) + v2

  pre_possible_action(sentence)
    return a dictionary where key is the noun appeared in the sentence and value is possible actions of the key

  problem 1:
    When using SpaCy to recognize noun in a sentence, some noun might be more than one word. Therefore, in the pre_possible_action function, I figure there are two possible way to resolve this problem. One is by connect them(using underscore) and use as a whole word to do prediction. The other choice was predict with the root word. see the code below:
      try:
          dictionary[word] = predict_words(canons, word, 1)
      except:
          dictionary[word] = predict_words(canons, chunk.root.text, 1)
    I therefore run a test on both to see their performance.
    SOLVED: most of the underscore version words do not have vector in the model

  problem 2:
    One of the common problem of these function being that we can not guarantee the output word be the kind of word (e.g. verb) we’d like. At the moment, I believe spaCy cannot detect word’s tag not in a sentence. Thus, I haven’t figure out a nice way to resolve this problem, Any idea on this issue?

    Also, for the same issue, weirdly Fulda has a perfect output with all verbs. I assume it's either because of the model that we used or some undocumented method that Fulda adopted.

      Fulda's prediction on "sword"
        [‘vanquish’, ‘duel’, ‘unsheathe’, ‘wield’, ‘summon’, ‘behead’, ‘battle’, ‘impale’, ‘overpower’, ‘cloak’]
      Our prediction on "sword":
        canon :: [unsheathe] : sword)
        canon :: [swords] : sword)
        canon :: [impale] : sword)
        canon :: [overpower] : sword)
        canon :: [wear] : sword)
        canon :: [Damocles_hangs] : sword)
        canon :: [vanquish] : sword)
        canon :: [sheathe] : sword)
        canon :: [don] : sword)
        canon :: [wield] : sword)
        canon :: [gallop] : horse)
    SOLVED: check Algorism 2 by Fulda. (I think this will be partly my next week work)

  proposing next week work:
    1, Replicate algorism 2 by Fulda
    2, Replicate graspable noun by Fulfa
    3, what you would suggest and how you think the research shall go? I'm kinda lost in the realm of replicating her work.

    btw, I checked her information. She is so cool!!! Ready to read her fictions!

Dec 13, 2017 Updates
  1, In this update, I replicated Fulda's algotithm on finding proper verbs. I download a list that contains top 1000 commonly used english words. When there the model returns a list of possible verbs, the algorithm will check if these words are in the list or not. If contains, the word will be add to the word2vec_word list. Otherwise, the word will be abandoned.
  In Fulda's paper, she also union the list with other commonly used verbs in interacive fiction to obtain the final_vebrs list. In this case, there will contain navigation verbs, which can be pretty useful in the future.
  Below are the naming of the verb set:
      word2vec verbs: the set of words return by using word2vec model
      affordant verbs: the set of verbs that is the intersection between word2vec verbs set and top 1000 english verbs
      final verbs: the set of verbs that unions navigation verbs, common manipulation verbs used in interactive fiction and affordant verbs found above.
  2, Note that at this moment, the returned list from get_adjectives_of_noun does not necessarily only contain adj. Similar situation also applies to get_tools_for_verb. 
  3, In this update, I use Natural Language Toolkit (nltk) to do the words lemmatization because I was playing with it. If you'd like, please install nltk to run the code. Otherwise, I will push a version with Spacy shortly.
  4, A more general question, how you think we shall combine word2vec and knowledge base together?

  To do next week: ?
