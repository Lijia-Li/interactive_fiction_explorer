{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-25 12:25:59,079 : INFO : loading projection weights from ./model/GoogleNews-vectors-negative300.bin\n",
      "2017-11-25 12:27:22,759 : INFO : loaded (3000000, 300) matrix from ./model/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import gensim\n",
    "# Login\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# loading model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-25 12:27:22,803 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stucco', 0.41667330265045166), ('mortar_booksellers', 0.41204798221588135), ('tile_flooring', 0.4049796462059021)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['forest', 'brick'], negative=['tree'], topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her\n",
      "worse\n",
      "were\n"
     ]
    }
   ],
   "source": [
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(he is to his) as (she is to her)\n",
      "(big is to bigger) as (bad is to worse)\n",
      "(going is to went) as (being is to were)\n"
     ]
    }
   ],
   "source": [
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    # print(predicted)\n",
    "    print ('({} is to {}) as ({} is to {})'.format(a, b, x, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sing : song :: Efforting_soundbites : [video]\n",
      "drink : water :: videos : [video]\n",
      "read : book :: Efforting_soundbites : [video]\n",
      "eat : food :: Efforting_soundbites : [video]\n",
      "wear : coat :: videos : [video]\n",
      "drive : car :: Efforting_soundbites : [video]\n",
      "ride : horse :: videos : [video]\n",
      "give : gift :: videos : [video]\n",
      "attack : enemy :: videos : [video]\n",
      "say : word :: INCLUDES_previously_unreleased : [video]\n",
      "open : door :: videos : [video]\n",
      "climb : tree :: videos : [video]\n",
      "heal : wound :: Video : [video]\n",
      "cure : disease :: Video : [video]\n",
      "paint : picture :: videos : [video]\n",
      "--------------------------------------------\n",
      "canon :: [videos] : video)\n",
      "canon :: [Efforting_soundbites] : video)\n",
      "canon :: [upload_videos] : video)\n",
      "canon :: [INCLUDES_previously_unreleased] : video)\n",
      "canon :: [live_stream_sopcast] : video)\n",
      "canon :: [upload] : video)\n",
      "canon :: [I'ma_Trekkie] : video)\n",
      "canon :: [watch] : video)\n",
      "canon :: [DivX_encoded] : video)\n",
      "canon :: [Quicktime_format] : video)\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"sing song\", \"drink water\", \"read book\", \"eat food\", \"wear coat\", \"drive car\", \"ride horse\", \"give gift\", \"attack enemy\", \"say word\", \"open door\", \"climb tree\", \"heal wound\", \"cure disease\", \"paint picture\"]\n",
    "# canons should be a list of pair of \"noun verb\"\n",
    "def more_verb (conons, n2):\n",
    "    m = 0\n",
    "    sigma = 0\n",
    "    for pair in conons:\n",
    "        v1, n1 = pair.split()\n",
    "        sigma += model.word_vec(v1) - model.word_vec(n1)\n",
    "        m += 1\n",
    "        predicted = model.most_similar([n2, v1], [n1])[0][0]\n",
    "        print ('{} : {} :: [{}] : {}'.format(v1, n1, predicted, n2))\n",
    "    a = (1/m)*sigma\n",
    "    predicted = model.most_similar([a, n2], [])\n",
    "    print(\"--------------------------------------------\")\n",
    "    for i in range(10):\n",
    "        print ('canon :: [{}] : {})'.format(predicted[i][0], n2))\n",
    "more_verb(word_list, \"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('adore', 0.5517649054527283), ('enjoy', 0.5034534931182861), ('cherish', 0.49044713377952576), ('despise', 0.47901347279548645), ('loved', 0.46845656633377075), ('loves', 0.4619172215461731), ('critisize', 0.45148664712905884), ('appreciate', 0.4504649043083191), ('admire', 0.4498775601387024), ('eat', 0.44955557584762573)]\n"
     ]
    }
   ],
   "source": [
    "def predict_verbs (conons, n2):\n",
    "    m = 0\n",
    "    sigma = 0\n",
    "    for pair in conons:\n",
    "        v1, n1 = pair.split()\n",
    "        sigma += model.word_vec(v1) - model.word_vec(n1)\n",
    "        m += 1\n",
    "    a = (1/m)*sigma\n",
    "    predicted = model.most_similar([a, n2], [], topn = 10)\n",
    "    print(predicted)\n",
    "    \n",
    "predict_verbs(word_list, \"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tome', 0.5465936064720154), ('memoir', 0.5445234179496765), ('books', 0.5256607532501221), ('manuscript', 0.5182934403419495), ('hardcover_edition', 0.49704527854919434), ('Book', 0.49279889464378357), ('unpublished_manuscript', 0.4919023811817169), ('Lace_Reader', 0.4913598895072937), ('hardback', 0.486393004655838), ('flyleaf', 0.4828701913356781)]\n",
      "[('write', 0.486385703086853), ('read', 0.46074622869491577), ('take', 0.41436272859573364), ('publish', 0.4090305268764496), ('eat', 0.40674889087677), ('Gordon_Korman', 0.4022621214389801), ('devour', 0.39084985852241516), ('books', 0.38471636176109314), ('teach', 0.3764316439628601), ('tome', 0.37393248081207275)]\n"
     ]
    }
   ],
   "source": [
    "def predict_words (conons, word, pre_verb):\n",
    "    m = 0\n",
    "    sigma = 0\n",
    "    for pair in conons:\n",
    "        v1, n1 = pair.split()\n",
    "        sigma += model.word_vec(v1) - model.word_vec(n1)\n",
    "        m += 1\n",
    "    a = (1/m)*sigma\n",
    "    if pre_verb == 1:\n",
    "        predicted = model.most_similar([a, word], [], topn = 10)\n",
    "    elif pre_verb == 0:\n",
    "        predicted = model.most_similar([word], [a], topn = 10)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def main():\n",
    "    word_list = [\"sing song\", \"drink water\", \"read book\", \"eat food\", \"wear coat\", \"drive car\", \"ride horse\", \"give gift\",\n",
    "                 \"attack enemy\", \"say word\", \"open door\", \"climb tree\", \"heal wound\", \"cure disease\", \"paint picture\"]\n",
    "#     demo_more_verb(word_list, \"book\")\n",
    "    list = [\"book\", \"day\", \"fun\"]\n",
    "    print(predict_words(word_list, \"book\", pre_verb = 0))\n",
    "    print(predict_words(word_list, \"book\", pre_verb = 1))\n",
    "\n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}